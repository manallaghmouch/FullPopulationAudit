{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 Define input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Declare4Py.ProcessModels.DeclareModel import DeclareModel\n",
    "from Declare4Py.D4PyEventLog import D4PyEventLog\n",
    "from Declare4Py.ProcessMiningTasks.ConformanceChecking.MPDeclareAnalyzer import MPDeclareAnalyzer\n",
    "from Declare4Py.ProcessMiningTasks.ConformanceChecking.MPDeclareResultsBrowser import MPDeclareResultsBrowser \n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of created logs\n",
    "num_logs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Conformance checking (log vs. normative model (deviations) & log vs. auditor model (anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store created dataframes\n",
    "df_norm_dict = {}\n",
    "df_audit_dict = {}\n",
    "\n",
    "eventlog_dict = {}\n",
    "\n",
    "# Loop through each event log\n",
    "for h in range(1, num_logs + 1):  # number of created logs + 1 \n",
    "    source_file = f'eventlog_model{h}.xes'\n",
    "    \n",
    "    # Check if source file exists (to avoid errors)\n",
    "    if os.path.exists(source_file):\n",
    "        log_path = os.path.join(source_file)\n",
    "        event_log = D4PyEventLog(case_name=\"case:concept:name\")\n",
    "        event_log.parse_xes_log(log_path)\n",
    "\n",
    "        # # Initialize dictionaries for this event log\n",
    "        # df_norm_dict[h] = {}\n",
    "        # df_audit_dict[h] = {}\n",
    "\n",
    "        for j in range(1,3): # j == 1 (normative model), j == 2 (auditor model)\n",
    "            model_file = f'model{h}_{j}.decl'\n",
    "\n",
    "            if os.path.exists(model_file):\n",
    "                model_path = os.path.join(model_file)\n",
    "                declare_model = DeclareModel().parse_from_file(model_path)\n",
    "\n",
    "                basic_checker = MPDeclareAnalyzer(log=event_log, declare_model=declare_model, consider_vacuity=True)\n",
    "                conf_check_res: MPDeclareResultsBrowser = basic_checker.run()\n",
    "\n",
    "                if j == 1: \n",
    "                    df_norm = conf_check_res.get_metric(metric=\"state\")\n",
    "                    df_norm_dict[h] = df_norm\n",
    "                    # globals()[f'df_norm_L{h}_M{i}'] = df_norm\n",
    "                    df_norm.to_csv(f'CC_normative_{h}.csv')\n",
    "                else: \n",
    "                    df_audit = conf_check_res.get_metric(metric=\"state\")\n",
    "                    df_audit_dict[h] = df_audit\n",
    "                    # globals()[f'df_audit_L{h}_M{i}'] = df_audit\n",
    "                    df_audit.to_csv(f'CC_audit_{h}.csv')\n",
    "\n",
    "            else:\n",
    "                print(f\"Source file {model_file} does not exist. Skipping set {i}.\")\n",
    "\n",
    "        # Transform each event log to a dataframe (needed in a later step)\n",
    "        event_log.to_dataframe()\n",
    "        df_log = event_log.get_log() \n",
    "\n",
    "        # Store eventlogs in a dictionary\n",
    "        eventlog_dict[h] = df_log\n",
    "\n",
    "    else:\n",
    "        print(f\"Source file {source_file} does not exist. Skipping set {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conformant cases with normative model: \" +  str(df_norm_dict[2][1].loc[(df_norm_dict[2][1]==1).all(axis=1)].shape[0]) + \n",
    "      \"\\nNon-conformant cases with normative model: \" + str(df_norm_dict[2][1].loc[(df_norm_dict[2][1]==0).any(axis=1)].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conformant with auditor model: \" +  str(df_audit_dict[2][1].loc[(df_audit_dict[2][1]==1).all(axis=1)].shape[0]) + \n",
    "      \"\\nNon-conformant with auditor model: \" + str(df_audit_dict[2][1].loc[(df_audit_dict[2][1]==0).any(axis=1)].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Label deviations as Anomaly (1) or Exception (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set percentage anomalies\n",
    "percent_anomalies = 0.05\n",
    "random.seed(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store created dataframes of labeled deviations\n",
    "deviations_dict = {}\n",
    "\n",
    "\n",
    "for h in range(1, num_logs+1): # number of logs + 1\n",
    "\n",
    "    # Initialize dictionary\n",
    "    # deviations_dict[h] = {}\n",
    "    \n",
    "\n",
    "    # Look up eventlog needed for this iteration\n",
    "    eventlog = eventlog_dict[h].copy(deep = True)\n",
    "    \n",
    "    # Format case_id such that only integer value is shown\n",
    "    eventlog['case:concept:name'] = eventlog['case:concept:name'].str.replace('case_', '')\n",
    "    eventlog['case:concept:name'] = eventlog['case:concept:name'].astype(int)\n",
    "\n",
    "\n",
    "    # Look up df_norm and df_audit that belong to the created eventlog\n",
    "    df_norm = df_norm_dict[h]\n",
    "    df_audit = df_audit_dict[h]\n",
    "\n",
    "\n",
    "    # Get deviations and anomalies\n",
    "    violations_norm = df_norm[(df_norm == 0).any(axis='columns')]\n",
    "    violations_auditor = df_audit[(df_audit == 0).any(axis='columns')]\n",
    "\n",
    "    # Generate lists to get indices\n",
    "    deviations = violations_norm.index.values.tolist() \n",
    "    anomalies = violations_auditor.index.values.tolist() \n",
    "    exceptions = np.setdiff1d(deviations, anomalies) # find the set difference of two arrays: return unique values in array 1 that are not in array 2\n",
    "\n",
    "    # print(len(anomalies) + len(exceptions))\n",
    "    # print(len(deviations))\n",
    "\n",
    "    # Add column that indicates whether case is a deviation or not\n",
    "    eventlog['deviation'] = np.where(eventlog['case:concept:name'].isin(deviations), 1, 0)\n",
    "    eventlog = eventlog[eventlog.deviation != 0]\n",
    "    \n",
    "    # print(len(eventlog)) # without conformant cases - so actually deviation log\n",
    "\n",
    "    # Add column that indicates whether case is an anomaly or not\n",
    "    eventlog['anomaly'] = np.where(eventlog['case:concept:name'].isin(anomalies), 1, 0)\n",
    "\n",
    "    # print(anomalies)\n",
    "    # print(len(anomalies))\n",
    "\n",
    "    # set number of anomalies and exceptions in entire dataset\n",
    "    num_anomalies = len(anomalies)\n",
    "    num_exceptions = len(exceptions)\n",
    "    num_deviations = num_anomalies + num_exceptions\n",
    "\n",
    "    # # Check label distribution\n",
    "    # print(\"Number of anomalies: \" + str(num_anomalies) + \n",
    "    #     \"\\nNumber of exceptions: \" + str(num_exceptions))\n",
    "\n",
    "    \n",
    "    if num_anomalies != 0 ^ num_exceptions != 0:\n",
    "        if num_anomalies >= (percent_anomalies * num_exceptions):\n",
    "            # adjusted_num_anomalies = round(percent_anomalies * num_exceptions)\n",
    "            # adjusted_num_exceptions = num_exceptions - adjusted_num_anomalies\n",
    "\n",
    "            adjusted_num_anomalies = round((percent_anomalies * num_exceptions) / (1 - percent_anomalies))\n",
    "            adjusted_num_exceptions = num_exceptions \n",
    "        else: \n",
    "            adjusted_num_anomalies = num_anomalies\n",
    "            adjusted_num_exceptions = round((num_anomalies / percent_anomalies) - num_anomalies)\n",
    "\n",
    "        # actual_percent = adjusted_num_anomalies / (adjusted_num_anomalies + adjusted_num_exceptions)\n",
    "        # print(\"Actual percentage anomalies: \" + str(actual_percent))\n",
    "\n",
    "        # print(\"Adjusted number of anomalies: \" + str(adjusted_num_anomalies))\n",
    "        # print(\"Adjusted number of exceptions: \" + str(adjusted_num_exceptions))\n",
    "\n",
    "\n",
    "        # Get df with anomalies only (take into account adjustments)\n",
    "        anomalies_df = eventlog[eventlog['anomaly']==1]\n",
    "        adjusted_anomalies = random.sample(sorted(anomalies), adjusted_num_anomalies)\n",
    "        anomalies_df['to_keep'] = np.where(anomalies_df['case:concept:name'].isin(adjusted_anomalies), 1, 0)\n",
    "\n",
    "        anomalies_df_new = anomalies_df[anomalies_df['to_keep']==1]\n",
    "        final_anomalies = anomalies_df_new.drop(['deviation', 'to_keep'],axis='columns')\n",
    "\n",
    "        # print(len(final_anomalies))\n",
    "\n",
    "        # Get df with exceptions only (take into account adjustments)\n",
    "        exceptions_df = eventlog[eventlog['anomaly']==0] \n",
    "        adjusted_exceptions = random.sample(sorted(exceptions), adjusted_num_exceptions)\n",
    "        exceptions_df['to_keep'] = np.where(exceptions_df['case:concept:name'].isin(adjusted_exceptions), 1, 0)\n",
    "\n",
    "        exception_df_new = exceptions_df[exceptions_df['to_keep']==1]\n",
    "        final_exceptions = exception_df_new.drop(['deviation', 'to_keep'],axis='columns')\n",
    "\n",
    "        # Obtain labeled log of deviations\n",
    "        labeled_deviations = pd.concat([final_anomalies,final_exceptions])\n",
    "\n",
    "        # Create global variable \n",
    "        deviations_dict[h] = labeled_deviations\n",
    "        \n",
    "        # Save file \n",
    "        labeled_deviations.to_csv(f'labeled_deviations_{h}.csv')\n",
    "\n",
    "        # else: \n",
    "        #     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Transform event log to trace log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store created dataframes\n",
    "traces_dict = {}\n",
    "\n",
    "# loop over verschillende df_norm's en df_audit's \n",
    "for h in range(1, num_logs+1):  \n",
    "    \n",
    "    if h in deviations_dict.keys():\n",
    "    \n",
    "        # traces_dict[h] = {}\n",
    "\n",
    "        deviations = deviations_dict[h]\n",
    "\n",
    "        df_audit = df_audit_dict[h]\n",
    "        \n",
    "        # convert 'time:timestamp' to datetime\n",
    "        deviations['time:timestamp'] = pd.to_datetime(deviations['time:timestamp'],format=\"ISO8601\")\n",
    "        deviations_sorted = deviations.groupby('case:concept:name').apply(lambda x: x.sort_values('time:timestamp')).reset_index(drop=True)\n",
    "\n",
    "        # transform event log to trace log\n",
    "        traces = deviations_sorted.groupby('case:concept:name').agg({\n",
    "            'concept:name': lambda x: f\"<{', '.join(x)}>\",\n",
    "            'anomaly': 'first'\n",
    "            }).reset_index()\n",
    "        traces.columns = ['case:concept:name', 'trace', 'label']\n",
    "\n",
    "        # merge trace log and results conformance checking\n",
    "        labeled_traces = pd.merge(left=traces, right=df_audit, how=\"left\", left_on=\"case:concept:name\", right_index=True)\n",
    "\n",
    "        traces_dict[h] = labeled_traces\n",
    "\n",
    "        # Save file\n",
    "        labeled_traces.to_csv(f'labeled_traces_{h}.csv', index=False)\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
